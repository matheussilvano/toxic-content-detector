# ğŸ§  Detector de ConteÃºdo TÃ³xico

Este Ã© um projeto de Machine Learning para **detecÃ§Ã£o de comentÃ¡rios tÃ³xicos** usando NLP com Python e uma interface interativa com Streamlit. Ele utiliza **RegressÃ£o LogÃ­stica** e **TF-IDF** para classificar comentÃ¡rios como **tÃ³xicos ou nÃ£o tÃ³xicos**.

VocÃª pode testar a aplicaÃ§Ã£o online atravÃ©s do seguinte link: [Detector de ConteÃºdo TÃ³xico](https://toxic-content-detector.streamlit.app/)

![image](https://github.com/user-attachments/assets/1ad55696-674e-4d16-aa86-0364d5693552)

---

## ğŸš€ Funcionalidades

- PrÃ©-processamento de texto com NLTK.
- VetorizaÃ§Ã£o com TF-IDF.
- Modelo de RegressÃ£o LogÃ­stica para classificaÃ§Ã£o binÃ¡ria.
- Interface grÃ¡fica com Streamlit.
- Treinamento e salvamento de modelo e vetorizador com `joblib`.

---

## ğŸ“ Estrutura do Projeto

```
toxic-content-detector/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Interface com Streamlit
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.csv               # Base de dados de treino
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_model.pkl      # Modelo treinado
â”‚   â””â”€â”€ vectorizer.pkl          # Vetorizador TF-IDF treinado
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py        # FunÃ§Ã£o de limpeza de texto
â”‚   â”œâ”€â”€ predict.py              # FunÃ§Ã£o de prediÃ§Ã£o
|   â””â”€â”€train_model.py           # Script de treinamento
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```
---

## ğŸ§¼ PrÃ©-processamento de Texto

O texto Ã© limpo com os seguintes passos:

- RemoÃ§Ã£o de URLs
- RemoÃ§Ã£o de caracteres especiais e nÃºmeros
- ConversÃ£o para minÃºsculas
- RemoÃ§Ã£o de stopwords (palavras comuns como "the", "and", etc.)
- StemizaÃ§Ã£o (reduz palavras Ã  sua raiz)

---

## ğŸ“¦ Docker

### Build da imagem

```bash
docker build -t toxic-content-detector .
```

### Rodar o container

```bash
docker run -p 8501:8501 toxic-content-detector
```

---

## ğŸ“Š Dataset

O modelo foi treinado com um subconjunto do dataset **[Jigsaw Toxic Comment Classification Challenge (Kaggle)](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)**.

A base de dados estÃ¡ na pasta `/data`

---

## ğŸ›  Tecnologias

- Python
- Pandas
- scikit-learn
- NLTK
- Streamlit
- Docker

---

ğŸ§  O modelo (`models/logistic_model.pkl`) jÃ¡ estÃ¡ treinado e pronto para uso.
Caso deseje treinÃ¡-lo novamente, execute:

python src/train_model.py

